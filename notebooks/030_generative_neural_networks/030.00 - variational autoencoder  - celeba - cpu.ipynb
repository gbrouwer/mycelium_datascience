{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfNT-mlFwxVM"
   },
   "source": [
    "# Variational Autoencoder - CelebA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import visdom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from lib_cpu.utils import CroppedCelebA\n",
    "from lib_cpu.models.VAE import VAE\n",
    "plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'VAE'\n",
    "n_epochs=1\n",
    "start_epoch=0\n",
    "batch_size=128\n",
    "lr=0.0001\n",
    "beta1=0.5\n",
    "beta2=0.999\n",
    "n_fil=128\n",
    "z_dim=88\n",
    "n_critic=5\n",
    "n_gen=1                     \n",
    "use_visdomt=True\n",
    "visdom_host='http://localhost'\n",
    "visdom_port=8097\n",
    "visdom_env='main'\n",
    "plot_freq=100\n",
    "chkp_freq=1\n",
    "preload_model=False\n",
    "load_dir = '../../data/celeba/models/'\n",
    "save_dir= '../../data/celeba/models/'\n",
    "imgs_dir = '../../data/celeba/generated/'\n",
    "choices=['VAE', 'DCGAN', 'VAEGAN', 'LSGAN', 'WGAN', 'WGANGP', \"InfoGAN\", 'BEGAN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "n_attrs = 40\n",
    "viz = visdom.Visdom(server=visdom_host, port=visdom_port, env=visdom_env)\n",
    "celeba_data = CroppedCelebA(\"../../data/celeba/\")\n",
    "model = VAE(n_fil, z_dim, n_attrs, viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_optimizers(lr, beta1, beta2)\n",
    "model.n_gen = n_gen\n",
    "model.n_critic = n_critic\n",
    "if preload_model:\n",
    "    model.load(load_dir, args.start_epoch-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '035574.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mceleba_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgs_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mchkp_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchkp_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_freq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave(save_dir)\n",
      "File \u001b[0;32m~/Projects/mycelium_datascience/notebooks/030_generative_neural_networks/lib_cpu/BaseModels.py:185\u001b[0m, in \u001b[0;36mBaseModel.train_model\u001b[0;34m(self, celeba_data, n_epochs, batch_size, start_epoch, models_dir, imgs_dir, chkp_freq, plot_freq)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_const \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG\u001b[38;5;241m.\u001b[39mz_dim)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs_const \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs_const \u001b[38;5;241m=\u001b[39m Variable(\u001b[43mceleba_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;66;03m#.cuda()\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch \u001b[38;5;241m+\u001b[39m n_epochs):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/mycelium_datascience/notebooks/030_generative_neural_networks/lib_cpu/utils.py:41\u001b[0m, in \u001b[0;36mCelebA.get_random_attrs\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_random_attrs\u001b[39m(\u001b[38;5;28mself\u001b[39m, num):\n\u001b[0;32m---> 41\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attrs\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '035574.jpg'"
     ]
    }
   ],
   "source": [
    "model.train_model(celeba_data, n_epochs=n_epochs, batch_size=batch_size,\n",
    "                  start_epoch=start_epoch,\n",
    "                  models_dir=save_dir, imgs_dir=imgs_dir,\n",
    "                  chkp_freq=chkp_freq, plot_freq=plot_freq)\n",
    "model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
